## 🔹 بخش 4: **انحراف معیار (Standard Deviation)**

### 📌 تعریف:
جذر واریانس است و واحد داده‌ها را حفظ می‌کند.

### ✅ فرمول:

$$
\sigma = \sqrt{\sigma^2}, \quad s = \sqrt{s^2}
$$

### 💡 ادامه مثال:

از قبل داشتیم:
- واریانس جامعه: $ \sigma^2 = 0.6667 $
- واریانس نمونه: $ s^2 = 1 $

پس:

- انحراف معیار جامعه:  
$$
\sigma = \sqrt{0.6667} \approx 0.816
$$

- انحراف معیار نمونه:  
$$
s = \sqrt{1} = 1
$$

✅ پس انحراف معیار:
- جامعه: **0.816**
- نمونه: **1**

---

## 🔹 بخش 5: **همبستگی (Correlation)**

### 📌 تعریف:
همبستگی نشان‌دهنده شباهت خطی بین دو سیگنال است. عددی بین $-1$ تا $+1$.

### ✅ فرمول:

$$
r_{xy} = \frac{\text{Cov}(x, y)}{\sigma_x \cdot \sigma_y}
$$

که:
- $\text{Cov}(x, y)$: کواریانس بین دو سیگنال
- $\sigma_x, \sigma_y$: انحراف معیار هر سیگنال

### 💡 مثال:

فرض کنید دو سیگنال داریم:

$$
x = [1, 2, 3], \quad y = [2, 4, 6]
$$

میانگین‌ها:
$$
\bar{x} = 2, \quad \bar{y} = 4
$$

تفاوت‌ها:
$$
(x - \bar{x}) = [-1, 0, 1], \quad (y - \bar{y}) = [-2, 0, 2]
$$

ضرب تفاوت‌ها:
$$
(-1)(-2) = 2, \quad (0)(0) = 0, \quad (1)(2) = 2
$$

جمع ضرب‌ها:
$$
\sum (x - \bar{x})(y - \bar{y}) = 2 + 0 + 2 = 4
$$

تقسیم بر $ N-1 = 2 $:
$$
\text{Cov}(x, y) = \frac{4}{2} = 2
$$

انحراف معیار:
- $ \sigma_x = 1 $, $ \sigma_y = 2 $

همبستگی:
$$
r_{xy} = \frac{2}{1 \cdot 2} = 1
$$

✅ بنابراین همبستگی بین x و y برابر **1** است (یعنی کاملاً مثبت)

---

## 🔹 بخش 6: **PCA (تحلیل مؤلفه‌های اصلی)**

### 📌 هدف:
کاهش بعد داده‌ها با حفظ بیشترین اطلاعات (واریانس).

### ✅ مراحل محاسبه (دستی):

1. **مرکز کردن داده‌ها**: میانگین هر ستون را از مقادیر کم کن.
2. **محاسبه ماتریس کواریانس**.
3. **محاسبه مقادیر ویژه (Eigenvalues) و بردارهای ویژه (Eigenvectors)**.
4. **انتخاب k تا از بزرگترین مقادیر ویژه**.
5. **تصحیح داده‌ها روی این k مؤلفه**.

### 💡 مثال ساده:

فرض کنید داریم:

$$
X = \begin{bmatrix}
1 & 2 \\
3 & 4 \\
5 & 6
\end{bmatrix}
$$

#### ۱. میانگین ستون‌ها:
$$
\bar{x}_1 = \frac{1+3+5}{3} = 3, \quad \bar{x}_2 = \frac{2+4+6}{3} = 4
$$

#### ۲. مرکز کردن:
$$
X_m = \begin{bmatrix}
1-3 & 2-4 \\
3-3 & 4-4 \\
5-3 & 6-4
\end{bmatrix} =
\begin{bmatrix}
-2 & -2 \\
0 & 0 \\
2 & 2
\end{bmatrix}
$$

#### ۳. ماتریس کواریانس:
$$
C = \frac{1}{N-1} X_m^T X_m = \frac{1}{2} \begin{bmatrix}
8 & 8 \\
8 & 8
\end{bmatrix} =
\begin{bmatrix}
4 & 4 \\
4 & 4
\end{bmatrix}
$$

#### ۴. مقادیر ویژه:
معادله مشخصه:
$$
\det(C - \lambda I) = 0 \Rightarrow (4-\lambda)^2 - 16 = 0 \Rightarrow \lambda_1 = 8, \; \lambda_2 = 0
$$

#### ۵. بردار ویژه:
برای $ \lambda_1 = 8 $:
$$
v_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}
$$

#### ۶. تصحیح داده‌ها:
$$
Z = X_m \cdot v_1 = [-4, 0, 4]^T
$$

✅ بنابراین PCA یک بعد از دو بعد کاست و فقط مؤلفه مهم را نگه داشت.

---

## 🔹 بخش 7: **ICA (تحلیل مؤلفه‌های مستقل)**

### 📌 هدف:
جداسازی منابع مستقل از سیگنال‌های آمیخته (Blind Source Separation).

### ✅ ایده اصلی:

اگر داشته باشیم:

$$
x = A \cdot s
$$

که:
- $ x $: سیگنال‌های آمیخته
- $ A $: ماتریس اختلاط
- $ s $: منابع اصلی (ناشناس)

هدف یافتن $ W = A^{-1} $ است تا بتوانیم:

$$
s = W \cdot x
$$

### 💡 مثال ساده:

فرض کنید:

$$
x = \begin{bmatrix} 4 \\ 6 \\ 8 \end{bmatrix}, \quad A = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix}
$$

می‌خواهیم $ s $ را پیدا کنیم:

$$
s = A^{-1} \cdot x
$$

اما چون $ A $ مربع نیست، از روش‌های تقریبی مثل **روش کمترین مربعات** یا **ICA** استفاده می‌کنیم.

---

## ✅ خلاصه نهایی

| عنصر | مقدار |
|------|--------|
| سیگنال اولیه | `x = [7, 6, 5]` |
| میانگین | `6` |
| سیگنال بدون میانگین | `[1, 0, -1]` |
| واریانس (جامعه) | `≈ 0.6667` |
| واریانس (نمونه) | `1` |
| انحراف معیار (جامعه) | `≈ 0.816` |
| انحراف معیار (نمونه) | `1` |

---

اگر خواستی این محاسبات را برای یک سیگنال واقعی یا داده‌های EEG واقعی انجام دهم، فقط بگو!